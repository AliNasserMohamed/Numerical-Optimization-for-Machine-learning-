# Numerical-Optimization-for-Machine-learning-
Numerical Optimization for Machine learning 

IN this Notebooks I am trying to implement Numerical Optimizers 

## In the first notbook gradient_descent_Implementation for LR Single and MultiVar

I implemented the following from scratch 

1- gradient descent in order to achieve the linear regression (Single and Multivariables) of a set of datapoints.


  ## In the second Notebook Variants Batch - Mini-Batch - Stochastic implementation

 - I implemented the gradient descent variants (Batch/Mini-Batch/Stochastic) in order to achieve the linear regression of a set of datapoints.

  ## In the third Notebook Momentum - NAG 

- I implemented  the accelerated gradient descent methods (Momentum and NAG)

## In the forth Notebook _Newton_BFGS

- I implemented Newton's Method Optimization or univariante
  
-  I implemented Newton's Method Optimization or Multivariate
  
- BFGS

  
  
